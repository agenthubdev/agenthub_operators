# HybridSearch

HybridSearch is a class derived from BaseOperator that runs a hybrid search using a combination of precomputed embeddings and ChatGPT to answer a specific query.

## Overview

The core functionality of HybridSearch is as follows:

1. It receives a query and an input (vector index).
2. Computes the embedding of the query.
3. Sorts the chunks by similarity (using `sort_chunks_by_similarity` utility function).
4. Selects the most relevant chunks based on the overall tokens count (using `select_most_relevant_chunks` utility function), so it doesn't exceed the model's token limit.
5. Constructs a prompt for ChatGPT that fits within the model's token limit.
6. Sends the prompt to the ChatGPT model and generates a response.
7. Stores the ChatGPT response as an output.

## Parameters

- **query**: `string`, the query to be answered by the model.

## Inputs

- **vector_index**: `dict`, a dictionary containing precomputed vector embeddings of the indexed chunks.

## Outputs

- **hybrid_search_chatgpt_response**: `string`, the response generated by the ChatGPT model after processing the query and context.

## Helper Methods and Functionality

1. **sort_chunks_by_similarity**: Given a query's embedding and a vector index, it sorts the chunks based on the similarity with the provided query embedding.
2. **count_tokens**: Counts the number of tokens in a string given the model's name.
3. **select_most_relevant_chunks**: Selects the most relevant chunks that can fit into a token budget.
4. **get_max_tokens_for_model**: Retrieves the maximum number of tokens allowed for a given model.
5. **ai_context.run_chat_completion**: Takes a constructed prompt and generates a response using the ChatGPT model.
6. **ai_context.set_output**: Sets the output key-value pair to return as part of this operator's output.

## Example Usage

```python
hybrid_search_operator = HybridSearch()
result = hybrid_search_operator.run_step(step, ai_context)

# The generated response from ChatGPT + Hybrid Search.
response = result['hybrid_search_chatgpt_response']
```